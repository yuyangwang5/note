# Subway: Minimizing Data Transfer during Out-of-GPU-Memory Graph Processing

## 引言 Introduction

GPU内存不够，一种解决方式是将过大的图进行分区，然后每次迭代中把分区加载入GPU内存中。优化该方式的一种方法为异步流式传输图数据，使得数据传输和GPU内核执行重叠。然而许多图应用中，计算成本显著小于数据传输成本，且迭代过程中计算量变化也非常大，由此重叠的好处被限制；另一个优化方法是直接减少CPU和GPU间的数据移动，GraphReduce和Graphie跟踪活跃的顶点、边分区，并仅将其加载到GPU内存。不过，由于幂律分布，大多数分区可能与一些高度数顶点连接，由此具有活跃性，由此加载入的分区中实际上活跃边并不多，也限制了这种优化方向。

另一种解决方案是利用统一内存，其允许GPU透明访问主机内存，内存页面会根据需求从内存迁移至GPU。然而这种方式也有限制，页面错误处理存在显著开销，且加载的内存页面也可能含有大量不活跃的边/顶点，浪费CPU-GPU传输带宽。

在本文中，会仅将活跃的边和顶点重组为子图加载入GPU内存中。传统认为重复生成子图代价太高，然和在GPU的帮助下，子图生成成本可以足够低；除此本文还会将异步带入到GPU内存的子图处理方案。子图加载入GPU内存后不断计算直到子图收敛，其可以帮助减少迭代次数。

这些技术会被集成到Subway系统中，Subway会以CSR格式表示图。

总之，本文贡献为：
1. 快速子图生成技术；
2. 异步处理子图策略。

## Subway

### 快速子图生成

许多图算法中，一个迭代通常只有一部分顶点是活跃的，而大多数迭代中，活跃顶点和活跃边的比例通常很低。由此，希望能将图的活跃部分抽离出来，只加载活跃部分到GPU。在GPU的帮助下，子图生成的成本是可以承受的。

Subway输入为CSR格式，顶点数据存放于GPU中，边数据存放于内存中。对于子图，我们引入SubCSR，表示CSR顶点导出的子集，如下图所示：

![CSR and SubCSR](./pic/2020%20Subway/1%20CSR%20and%20SubCSR.png "CSR and SubCSR")

虽然多了对子图顶点数组的访问，但这种计算开销会被子图生成的好处所抵消。

#### 子图生成算法

子图生成输入为CSR vertex[] edge[]、顶点活跃性标记数组 isActive[] 和度数数组 degree[] 过程如下图所示：

![子图生成示例](./pic/2020%20Subway/2%20子图生成示例.png "子图生成示例")

步骤1：创建subIndex[]，表示活跃顶点ID之后会放入的位置的下标。如图中，subIndex[7]=2，代表节点7会被放入新数组下标为2的位置；

步骤2：基于subIndex[]、isActive[] 和数组索引 tid 创建子图顶点数组 subVertex[]；

步骤3：将degree数组中活跃顶点度数保留，其余置为0，生成subDegree[]；

步骤4：在subDegree[]上进行前缀和计算，生成subOffset[]；

步骤5：结合isActive[] 和 offset[]，除去不活跃的顶点，将subOffset[]压缩成offset[]。

步骤6：将 edge[] 压缩为 subEdge[]。

这六个步骤都高度并行，可以利用GPU的并行性。

#### 成本分析
前五个步骤的复杂度都是O(|V|)，最后一个步骤的时间复杂度为O(|$E_{active}$|)。子图要加载的数据量为|$E_{active}$| + 2 * |$V_{active}$|。在SubCSR生成过程中，也需要数据传输，大小为2 * |$V_{active}$|。由此，减少的数据传输大小为  |E| - |$E_{active}$| - 4 * |$V_{active}$|。

随着活跃边的比率（设为$P_{active}$）增加，SubCSR生成成本增加，同时传输收益减少。实验评估，发现$P_{active}=80\%$为一个较通用的阈值，超过此阈值后将不会有任何收益。超过此阈值时，将禁用SubCSR的生成。

若生成的SubCSR依旧过大，会对其进行分区，将SubCSR分区逐个加载入GPU内存中处理。

### 异步子图处理

子图加载到GPU后，相对于主机内存中的其它图，是异步的。子图会不断迭代，直到没有活跃顶点。

异步模型不一定减少计算量，但相比于同步模型会减少子图的生成和加载。

#### 正确性

对于对值传播顺序敏感的算法，该异步策略不适用。异步策略已被证实适用于三类算法：图遍历、随机游走和图聚合。对于其它一些算法（如PageRank），需要进行一些更改。
PageRank在采用累积更新形式的算法后，也可以正确运行。

### Subway实现

Subway是对开源GPU图处理框架Tigr的扩展。若输入的图适合GPU内存，可以直接使用Tigr进行处理；且Tigr使用顶点为中心编程和CSR图表示，与Subway是一样的。子图生成中，第一步和第四步前缀和的计算使用到了Thrust库，第六步使用Pthread库实现并行压缩便数组。

Subway会自动检测输入图的大小。当图适合GPU内存时，会直接用Tigr；否则Tigr的优化将被禁用，系统只要以来Subway运行时来进行性能优化。

## 实验

### 统一内存分析

统一内存避免了加载不包含活跃边的内存页，数据传输量大大减少。但其主要受到两个因素限制。首先，当请求页面不在GPU中时，会触发页面错误。处理页面错误不仅涉及数据传输，还涉及TLB无效化和页面表的更新，可能需要数十微妙。实验统计，页面错误相关开销占总时间的23%至69%。除此，迁移的页面包含不活跃的边。减少页面大小可能有助于优化这个问题，但会增加页面错误处理开销。















