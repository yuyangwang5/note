# Scaph: Scalable GPU-Accelerated Graph Processing with Value-Driven Differential Scheduling

## 主要创新

1. 将子图区分为高价值子图和低价值子图，采用不同的计算方式，减少无用子图信息的传输；
2. 队列管理子图
3. 注意并利用NUMA对于CPU访问内存速度的影响

## 问题背景： 
现有图处理引擎专注于客服GPU内存容量限制，以支持大规模图处理；而host-GPU带宽没有被真正有效利用。

本研究认为，通过提高host-GPU带宽的有效利用率，可以显著提升GPU加速架构下对大规模图的处理性能。观察得到对于传入GPU的子图，大部分数据在当前甚至未来的迭代中不会被使用到。在Scaph中，子图会被分为高价值子图（当前和未来的迭代中会不断被使用，有许多有效信息）和低价值子图，高价值子图会将整个活跃子图传递到GPU，而低价值子图则只传递当前迭代激活节点的相关信息。

对于一个子图，我们把它的边分为三类：
* useful data(UD)，与活跃顶点相关的边。这些数据在当前迭代中会被使用，必须被传递到GPU；
* potentially useful data(PUD)，与子图未来的活跃顶点相关的边。PUD并不在当前迭代中使用，但如果不谨慎处理每一次都会被重复传输到GPU。
* never used data(NUD)，子图中永远不会再被使用的边数剧。

对于某子图，在经过多轮迭代后，三种边的占比会不断变化，如图所示：

![三类边占比](./pic/2020%20Scaph/0%20三类边占比.png "三类边占比")

我们希望做到的是：既要减少重复传递PUD，又要减少传递NUD。然而对于PUD，准确定位比较困难；由此希望通过过去和当前迭代中的UD大小来预测PUD大小。

## 子图价值量化

Scaph强调基于价值的数据传输，所以子图的量化应该能够反映带宽的有效利用情况。

如果子图G是高价值子图，其在GPU上的吞吐量可表示为：

$$
T_{HV}(G) = \frac{|UD| + \lambda |PUD|}{|G|/BW + t_{barrier}}    
$$

其中分母表示子图传输时间，BW表示带宽，$t_{barrier}$表示同步开销。分子表示G在GPU迭代时访问的UD和PUD数目，我们使用平衡因子 $\lambda$ 来衰减|PUD|数量，$0 \le \lambda \le 1$，表示实际访问的PUD数目。

如果子图G为低价值子图，其吞吐量表示为

$$
T_{LV}(G) = \frac{|UD|}{|UD|/BW + t_{barrier}}    
$$

当 $T_{HV}(G) \ge T_{LV}(G)$ 时，G为高价值子图，否则为低价值。将该不等式化简可得：

$$ |UD| + \lambda |PUD|(1 + \frac{t_{barrier}}{|UD|/BW}) \gt |G|$$

可知关键在于确认|PUD|。然而|PUD|很难获得。

|PUD|通常是由|UD|激活的，所以我们可以根据同一子图的UD来启发式估计PUD。在本文种，满足以下两个条件之一，就将该子图视为高价值子图：

* $|UD|/|G| \gt \alpha$，这表明UD在图中占主导地位；
* $|UD_{cufrent}| - |UD_{last}| \gt 0$ 且 $|UD|/|G| \gt \beta$，表明UD数目为中等水平，且随着迭代增长有增加趋势。此时G也可以被视为高价值子图。

在实际操作中，$\alpha$、$\beta$经验取值为50%和30%。

## Scaph概述

每次迭代，调度器会将子图分为高价值和低价值两类，送到相应的引擎，每个引擎独立但同时将它们的子图调度到GPU上进行加速。

对于高价值子图，引擎使用队列辅助多轮处理；对于低价值子图，会在CPU上提取UD，将UD传递到GPU进行处理。

### 高价值子图处理

在GPU加速的异构架构下，子图必须足够小（通常为千万字节，实验将子图切为32MB），以实现细粒度的GPU调度.而在此时，简单地多次迭代一个小尺寸的子图通常无效，它不能利用来自其它子图的活跃顶点。

有观察是：当一个子图已经在GPU内存中时，经过一段延迟后再次调度会比重复处理更能充分利用PUD。由此，我们将使用队列来辅助多轮处理。

![图组织队列](./pic/2020%20Scaph/1%20图组织队列.png "图组织队列")

我们使用k级优先队列（$PQ_1$, $PQ_2$, ...$PQ_k$, ）来实现对GPU驻留子图的延迟重新调度，k表示所有子图迭代数中的最大值。由此，k在每次迭代中国可能不同。

在对子图价值估算完成后，会有高价值子图列表。对于列表中已经存在于GPU的子图，则会被重新放入$PQ_1$，否则将被放入到TransSet（等待被传入GPU）。

子图传输模块负责异步将TransSet的子图传输到GPU中。若有空闲空间就使用空闲空间，否则将会从多级队列中出队一个子图。传输的子图最开始都会被组织于$PQ_1$。

子图调度模块负责调度$PQ_1$, $PQ_2$, ...$PQ_k$中的子图。首先会处理$PQ_1$中的子图。若PQ1为空，调度器会从非空$PQ_i$（i为最小值）中出队一个子图。$PQ_1$的数据传输会和$PQ_2$,...$PQ_k$的计算尽可能重叠。子图一旦被处理，其优先级会下降一级。

### 低价值子图处理

低价值的子图关键在于高效提取UD。由于非统一内存访问(NUMA)，直接扫描子图中所有顶点以提取UD的方式成本较高。此外，不同子图的UD数目不同，还会导致各个子图负载不平衡的问题。

每个NUMA节点由一个CPU插槽和自己的内存库组成。在划分好图后，会先将子图均匀分布于不同的NUMA节点上。为了提高性能并改善节点内的负载均衡，每个子图的UD提取在自己的线程中进行，该线程会绑定到存储该子图的NUMA节点。提取通过位图锁定活跃顶点信息。

低价值子图会生成大小各异的UD子图。为了减少碎片化，Scaph将用于存储子图的chunk分割为更小的tile（分成32份）。在存储UD组成的子图时，会先尝试在一个未完全填充的chunk中找到连续的块，之后才使用空chunk。






























































